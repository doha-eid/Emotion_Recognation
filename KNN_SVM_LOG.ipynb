{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('Final_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psdbeta_9</th>\n",
       "      <th>psdbeta_13</th>\n",
       "      <th>psdtheta_13</th>\n",
       "      <th>psdtheta_3</th>\n",
       "      <th>psdalpha_9</th>\n",
       "      <th>psdalpha_3</th>\n",
       "      <th>psdalpha_7</th>\n",
       "      <th>psdbeta_5</th>\n",
       "      <th>psdalpha_13</th>\n",
       "      <th>psdalpha_8</th>\n",
       "      <th>...</th>\n",
       "      <th>HRV_CVI</th>\n",
       "      <th>HRV_Prc80NN</th>\n",
       "      <th>HRV_HF</th>\n",
       "      <th>HRV_Ca</th>\n",
       "      <th>HRV_LFHF</th>\n",
       "      <th>HRV_SD1a</th>\n",
       "      <th>HRV_S</th>\n",
       "      <th>HRV_MadNN</th>\n",
       "      <th>HRV_SD2a</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.353098</td>\n",
       "      <td>-0.419732</td>\n",
       "      <td>-0.343952</td>\n",
       "      <td>-0.475254</td>\n",
       "      <td>-0.373330</td>\n",
       "      <td>-0.468150</td>\n",
       "      <td>-0.261720</td>\n",
       "      <td>-0.279274</td>\n",
       "      <td>-0.350667</td>\n",
       "      <td>-0.504424</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011948</td>\n",
       "      <td>1.005051</td>\n",
       "      <td>3.627621</td>\n",
       "      <td>1.049158</td>\n",
       "      <td>0.410145</td>\n",
       "      <td>1.077186</td>\n",
       "      <td>1.123119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.086576</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.164130</td>\n",
       "      <td>-0.175393</td>\n",
       "      <td>-0.111932</td>\n",
       "      <td>0.302383</td>\n",
       "      <td>0.038875</td>\n",
       "      <td>0.258150</td>\n",
       "      <td>-0.161049</td>\n",
       "      <td>-0.169434</td>\n",
       "      <td>-0.116607</td>\n",
       "      <td>0.018493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939026</td>\n",
       "      <td>0.894635</td>\n",
       "      <td>0.450490</td>\n",
       "      <td>0.992888</td>\n",
       "      <td>0.572625</td>\n",
       "      <td>0.643784</td>\n",
       "      <td>0.536757</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.835036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.027737</td>\n",
       "      <td>-0.117177</td>\n",
       "      <td>-0.128325</td>\n",
       "      <td>0.063157</td>\n",
       "      <td>0.033106</td>\n",
       "      <td>0.057745</td>\n",
       "      <td>-0.132559</td>\n",
       "      <td>-0.149021</td>\n",
       "      <td>-0.128255</td>\n",
       "      <td>-0.093871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988428</td>\n",
       "      <td>1.027902</td>\n",
       "      <td>4.489243</td>\n",
       "      <td>0.753055</td>\n",
       "      <td>0.717908</td>\n",
       "      <td>1.020287</td>\n",
       "      <td>0.888804</td>\n",
       "      <td>0.923684</td>\n",
       "      <td>0.762874</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.210938</td>\n",
       "      <td>-0.311654</td>\n",
       "      <td>-0.275669</td>\n",
       "      <td>-0.067104</td>\n",
       "      <td>-0.191371</td>\n",
       "      <td>-0.068218</td>\n",
       "      <td>-0.194850</td>\n",
       "      <td>-0.230109</td>\n",
       "      <td>-0.279672</td>\n",
       "      <td>-0.325007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957135</td>\n",
       "      <td>0.948635</td>\n",
       "      <td>0.717087</td>\n",
       "      <td>0.785177</td>\n",
       "      <td>1.222864</td>\n",
       "      <td>0.716231</td>\n",
       "      <td>0.652118</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.726417</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.203095</td>\n",
       "      <td>0.125982</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.314590</td>\n",
       "      <td>0.208960</td>\n",
       "      <td>0.301284</td>\n",
       "      <td>-0.017967</td>\n",
       "      <td>-0.054181</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.066537</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051062</td>\n",
       "      <td>1.075500</td>\n",
       "      <td>1.381814</td>\n",
       "      <td>0.980383</td>\n",
       "      <td>0.086450</td>\n",
       "      <td>1.428653</td>\n",
       "      <td>1.643596</td>\n",
       "      <td>1.238095</td>\n",
       "      <td>1.264587</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.428960</td>\n",
       "      <td>0.063415</td>\n",
       "      <td>0.175457</td>\n",
       "      <td>-0.282586</td>\n",
       "      <td>-0.368012</td>\n",
       "      <td>-0.281040</td>\n",
       "      <td>0.072221</td>\n",
       "      <td>-0.314611</td>\n",
       "      <td>0.173249</td>\n",
       "      <td>-0.318572</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006056</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.542216</td>\n",
       "      <td>1.377285</td>\n",
       "      <td>0.475373</td>\n",
       "      <td>1.126089</td>\n",
       "      <td>1.069732</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>1.399569</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.441018</td>\n",
       "      <td>-0.490378</td>\n",
       "      <td>-0.397149</td>\n",
       "      <td>-0.452527</td>\n",
       "      <td>-0.375395</td>\n",
       "      <td>-0.461703</td>\n",
       "      <td>-0.363734</td>\n",
       "      <td>-0.305926</td>\n",
       "      <td>-0.405788</td>\n",
       "      <td>-0.440295</td>\n",
       "      <td>...</td>\n",
       "      <td>1.093039</td>\n",
       "      <td>1.055042</td>\n",
       "      <td>45.577436</td>\n",
       "      <td>1.359336</td>\n",
       "      <td>0.589387</td>\n",
       "      <td>1.702592</td>\n",
       "      <td>2.730477</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>1.437567</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>-0.237420</td>\n",
       "      <td>-0.042684</td>\n",
       "      <td>-0.018424</td>\n",
       "      <td>0.225323</td>\n",
       "      <td>-0.196020</td>\n",
       "      <td>0.234515</td>\n",
       "      <td>-0.293675</td>\n",
       "      <td>-0.084264</td>\n",
       "      <td>-0.020970</td>\n",
       "      <td>-0.206560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.232263</td>\n",
       "      <td>1.006177</td>\n",
       "      <td>1.095624</td>\n",
       "      <td>1.101661</td>\n",
       "      <td>1.555066</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.344214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-0.417094</td>\n",
       "      <td>-0.480054</td>\n",
       "      <td>-0.405573</td>\n",
       "      <td>-0.238502</td>\n",
       "      <td>-0.356731</td>\n",
       "      <td>-0.241715</td>\n",
       "      <td>-0.260885</td>\n",
       "      <td>-0.278179</td>\n",
       "      <td>-0.413550</td>\n",
       "      <td>-0.372264</td>\n",
       "      <td>...</td>\n",
       "      <td>1.041377</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>2.565754</td>\n",
       "      <td>0.875462</td>\n",
       "      <td>0.771653</td>\n",
       "      <td>1.052785</td>\n",
       "      <td>1.565247</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>1.322039</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>-0.425324</td>\n",
       "      <td>-0.274331</td>\n",
       "      <td>-0.109047</td>\n",
       "      <td>-0.421094</td>\n",
       "      <td>-0.355026</td>\n",
       "      <td>-0.430512</td>\n",
       "      <td>0.582890</td>\n",
       "      <td>-0.297268</td>\n",
       "      <td>-0.123146</td>\n",
       "      <td>-0.425974</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015376</td>\n",
       "      <td>0.999177</td>\n",
       "      <td>5.362526</td>\n",
       "      <td>1.038337</td>\n",
       "      <td>1.669570</td>\n",
       "      <td>0.990997</td>\n",
       "      <td>1.183212</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>1.174618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     psdbeta_9  psdbeta_13  psdtheta_13  psdtheta_3  psdalpha_9  psdalpha_3  \\\n",
       "0    -0.353098   -0.419732    -0.343952   -0.475254   -0.373330   -0.468150   \n",
       "1    -0.164130   -0.175393    -0.111932    0.302383    0.038875    0.258150   \n",
       "2    -0.027737   -0.117177    -0.128325    0.063157    0.033106    0.057745   \n",
       "3    -0.210938   -0.311654    -0.275669   -0.067104   -0.191371   -0.068218   \n",
       "4     0.203095    0.125982     0.002496    0.314590    0.208960    0.301284   \n",
       "..         ...         ...          ...         ...         ...         ...   \n",
       "409  -0.428960    0.063415     0.175457   -0.282586   -0.368012   -0.281040   \n",
       "410  -0.441018   -0.490378    -0.397149   -0.452527   -0.375395   -0.461703   \n",
       "411  -0.237420   -0.042684    -0.018424    0.225323   -0.196020    0.234515   \n",
       "412  -0.417094   -0.480054    -0.405573   -0.238502   -0.356731   -0.241715   \n",
       "413  -0.425324   -0.274331    -0.109047   -0.421094   -0.355026   -0.430512   \n",
       "\n",
       "     psdalpha_7  psdbeta_5  psdalpha_13  psdalpha_8  ...   HRV_CVI  \\\n",
       "0     -0.261720  -0.279274    -0.350667   -0.504424  ...  1.011948   \n",
       "1     -0.161049  -0.169434    -0.116607    0.018493  ...  0.939026   \n",
       "2     -0.132559  -0.149021    -0.128255   -0.093871  ...  0.988428   \n",
       "3     -0.194850  -0.230109    -0.279672   -0.325007  ...  0.957135   \n",
       "4     -0.017967  -0.054181     0.011464    0.066537  ...  1.051062   \n",
       "..          ...        ...          ...         ...  ...       ...   \n",
       "409    0.072221  -0.314611     0.173249   -0.318572  ...  1.006056   \n",
       "410   -0.363734  -0.305926    -0.405788   -0.440295  ...  1.093039   \n",
       "411   -0.293675  -0.084264    -0.020970   -0.206560  ...  1.043203   \n",
       "412   -0.260885  -0.278179    -0.413550   -0.372264  ...  1.041377   \n",
       "413    0.582890  -0.297268    -0.123146   -0.425974  ...  1.015376   \n",
       "\n",
       "     HRV_Prc80NN     HRV_HF    HRV_Ca  HRV_LFHF  HRV_SD1a     HRV_S  \\\n",
       "0       1.005051   3.627621  1.049158  0.410145  1.077186  1.123119   \n",
       "1       0.894635   0.450490  0.992888  0.572625  0.643784  0.536757   \n",
       "2       1.027902   4.489243  0.753055  0.717908  1.020287  0.888804   \n",
       "3       0.948635   0.717087  0.785177  1.222864  0.716231  0.652118   \n",
       "4       1.075500   1.381814  0.980383  0.086450  1.428653  1.643596   \n",
       "..           ...        ...       ...       ...       ...       ...   \n",
       "409     0.965517   1.542216  1.377285  0.475373  1.126089  1.069732   \n",
       "410     1.055042  45.577436  1.359336  0.589387  1.702592  2.730477   \n",
       "411     1.000000   1.232263  1.006177  1.095624  1.101661  1.555066   \n",
       "412     0.985000   2.565754  0.875462  0.771653  1.052785  1.565247   \n",
       "413     0.999177   5.362526  1.038337  1.669570  0.990997  1.183212   \n",
       "\n",
       "     HRV_MadNN  HRV_SD2a  target  \n",
       "0     1.000000  1.086576       7  \n",
       "1     0.843750  0.835036       0  \n",
       "2     0.923684  0.762874       2  \n",
       "3     0.812500  0.726417       5  \n",
       "4     1.238095  1.264587       1  \n",
       "..         ...       ...     ...  \n",
       "409   1.225000  1.399569       4  \n",
       "410   0.805556  1.437567       5  \n",
       "411   1.500000  1.344214       1  \n",
       "412   1.181818  1.322039       8  \n",
       "413   0.983908  1.174618       0  \n",
       "\n",
       "[414 rows x 57 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.target\n",
    "X = data.drop('target' , axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model\n",
    "def Evaluate (y_test, prediction):\n",
    "    accuracy = accuracy_score(y_test, prediction)\n",
    "    precision = precision_score(y_test, prediction, average='weighted')\n",
    "    recall = recall_score(y_test, prediction, average='weighted')\n",
    "    f1 = f1_score(y_test, prediction, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the best k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "K = []\n",
    "training = []\n",
    "test = []\n",
    "scores = {}\n",
    "  \n",
    "for k in range(1, 21):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "  \n",
    "    training_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    K.append(k)\n",
    "  \n",
    "    training.append(training_score)\n",
    "    test.append(test_score)\n",
    "    scores[k] = [training_score, test_score]\n",
    "    \n",
    "plt.scatter(K, training, color ='k')\n",
    "plt.scatter(K, test, color ='g')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier\n",
    "def KNN(X_train, y_train, X_test, y_test, num_neighbors):\n",
    "    \n",
    "    # create the model\n",
    "    KNN = KNeighborsClassifier(n_neighbors = num_neighbors)\n",
    "    \n",
    "    # fit the model\n",
    "    KNN.fit(X_train, y_train)\n",
    "    \n",
    "    # get the accuracy\n",
    "    test_accuracy = KNN.score(X_test, y_test)\n",
    "    train_accuracy = KNN.score(X_train, y_train)\n",
    "    \n",
    "    # predict the values\n",
    "    prediction = KNN.predict(X_test)\n",
    "    \n",
    "    return test_accuracy, train_accuracy, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.896 0.9446366782006921\n"
     ]
    }
   ],
   "source": [
    "KNN_test, KNN_train, KNN_prediction = KNN(X_train, y_train, X_test, y_test, 6)\n",
    "print(KNN_test, KNN_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score, precision_score, recall_score, f1_score = Evaluate(y_test, KNN_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>89.6</td>\n",
       "      <td>90.997569</td>\n",
       "      <td>89.6</td>\n",
       "      <td>89.580559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Precision  Recall         F1\n",
       "0   KNN      89.6  90.997569    89.6  89.580559"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scores = {\n",
    "    \"Model\":[\"KNN\"],\\\n",
    "    \"Accuracy\":[accuracy_score*100],\\\n",
    "    \"Precision\":[precision_score*100],\\\n",
    "    \"Recall\":[recall_score*100],\\\n",
    "    \"F1\":[f1_score*100]\n",
    "    }\n",
    "\n",
    "Scores=pd.DataFrame(Scores)\n",
    "Scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM (X_train, y_train, X_test, y_test, kernel):\n",
    "\n",
    "    # create the model for multiclass classification\n",
    "    SVM = svm.SVC(kernel=kernel, C=1, decision_function_shape='ovo')\n",
    "    \n",
    "    # fit the model\n",
    "    SVM.fit(X_train, y_train)\n",
    "    \n",
    "    # get the accuracy\n",
    "    test_accuracy = SVM.score(X_test, y_test)\n",
    "    train_accuracy = SVM.score(X_train, y_train)\n",
    "    \n",
    "    # predict the values\n",
    "    prediction = SVM.predict(X_test)\n",
    "    \n",
    "    return test_accuracy, train_accuracy, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808 0.8961937716262975\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier using linear kernel\n",
    "SVM_linear_test, SVM_linear_train, SVM_linear_prediction = SVM(X_train, y_train, X_test, y_test, 'linear')\n",
    "print(SVM_linear_test, SVM_linear_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.464 0.5467128027681661\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier using RBF kernel\n",
    "SVM_rbf_test, SVM_rbf_train, SVM_rbf_prediction = SVM(X_train, y_train, X_test, y_test, 'rbf')\n",
    "print(SVM_rbf_test, SVM_rbf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.104 0.1453287197231834\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier using sigmoid kernel\n",
    "SVM_sigmoid_test, SVM_sigmoid_train, SVM_sigmoid_prediction = SVM(X_train, y_train, X_test, y_test, 'sigmoid')\n",
    "print(SVM_sigmoid_test, SVM_sigmoid_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.488 0.5501730103806228\n"
     ]
    }
   ],
   "source": [
    "# SVM classifier using polynomial kernel\n",
    "SVM_poly_test, SVM_poly_train, SVM_poly_prediction = SVM(X_train, y_train, X_test, y_test, 'poly')\n",
    "print(SVM_poly_test, SVM_poly_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy_score_poly, precision_score_poly, recall_score_poly, f1_score_poly \u001b[39m=\u001b[39m Evaluate(y_test, SVM_poly_prediction)\n\u001b[0;32m      3\u001b[0m accuracy_score_linear, precision_score_linear, recall_score_linear, f1_score_linear \u001b[39m=\u001b[39m Evaluate(y_test, SVM_linear_prediction)\n\u001b[0;32m      5\u001b[0m accuracy_score_sigmoid, precision_score_sigmoid, recall_score_sigmoid, f1_score_sigmoid \u001b[39m=\u001b[39m Evaluate(y_test, SVM_sigmoid_prediction)\n",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m, in \u001b[0;36mEvaluate\u001b[1;34m(y_test, prediction)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mEvaluate\u001b[39m (y_test, prediction):\n\u001b[1;32m----> 3\u001b[0m     accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, prediction)\n\u001b[0;32m      4\u001b[0m     precision \u001b[39m=\u001b[39m precision_score(y_test, prediction, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     recall \u001b[39m=\u001b[39m recall_score(y_test, prediction, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "accuracy_score_poly, precision_score_poly, recall_score_poly, f1_score_poly = Evaluate(y_test, SVM_poly_prediction)\n",
    "\n",
    "accuracy_score_linear, precision_score_linear, recall_score_linear, f1_score_linear = Evaluate(y_test, SVM_linear_prediction)\n",
    "\n",
    "accuracy_score_sigmoid, precision_score_sigmoid, recall_score_sigmoid, f1_score_sigmoid = Evaluate(y_test, SVM_sigmoid_prediction)\n",
    "\n",
    "accuracy_score_rbf, precision_score_rbf, recall_score_rbf, f1_score_rbf = Evaluate(y_test, SVM_rbf_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores = {\n",
    "    \"Model\":[\"Linear SVM\",\"RBF SVM\",\"Sigmoid SVM\",\"Poly SVM\"],\\\n",
    "    \"Accuracy\":[accuracy_score_linear*100, accuracy_score_rbf*100, accuracy_score_sigmoid*100, accuracy_score_poly*100],\\\n",
    "    \"Precision\":[precision_score_linear*100, precision_score_rbf*100, precision_score_sigmoid*100, precision_score_poly*100],\\\n",
    "    \"Recall\":[recall_score_linear*100, recall_score_rbf*100, recall_score_sigmoid*100, recall_score_poly*100],\\\n",
    "    \"F1\":[f1_score_linear*100, f1_score_rbf*100, f1_score_sigmoid*100, f1_score_poly*100]\n",
    "    }\n",
    "\n",
    "Scores=pd.DataFrame(Scores)\n",
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression (X_train, y_train, X_test, y_test):\n",
    "    # create the model\n",
    "    log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "    # fit the model\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # get the accuracy\n",
    "    test_accuracy = log_reg.score(X_test, y_test)\n",
    "    train_accuracy = log_reg.score(X_train, y_train)\n",
    "\n",
    "    # predict the values\n",
    "    prediction = log_reg.predict(X_test)\n",
    "\n",
    "    return test_accuracy, train_accuracy, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.5674740484429066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Partitiion\\Pycharm_virtualenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LOG_REG_test, LOG_REG_train, LOG_REG_prediction = Logistic_Regression(X_train, y_train, X_test, y_test)\n",
    "print(LOG_REG_test, LOG_REG_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy_score_LOG, precision_score_LOG,recall_score_LOG, f1_score_LOG  \u001b[39m=\u001b[39m Evaluate(y_test, LOG_REG_prediction)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(accuracy_score_LOG, precision_score_LOG,recall_score_LOG, f1_score_LOG)\n",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m, in \u001b[0;36mEvaluate\u001b[1;34m(y_test, prediction)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mEvaluate\u001b[39m (y_test, prediction):\n\u001b[1;32m----> 3\u001b[0m     accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, prediction)\n\u001b[0;32m      4\u001b[0m     precision \u001b[39m=\u001b[39m precision_score(y_test, prediction, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     recall \u001b[39m=\u001b[39m recall_score(y_test, prediction, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "accuracy_score_LOG, precision_score_LOG,recall_score_LOG, f1_score_LOG  = Evaluate(y_test, LOG_REG_prediction)\n",
    "print(accuracy_score_LOG, precision_score_LOG,recall_score_LOG, f1_score_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pycharm_virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
