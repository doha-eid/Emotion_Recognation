{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv('ECG.csv')\n",
    "X = df.drop(['target','Unnamed: 0'] , axis=1)\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decisionTree(x_train, y_train, x_test, y_test, first_class_index = 0):\n",
    "    classifiers = []\n",
    "    for i in range(0, 9):\n",
    "        clf = DecisionTreeClassifier()\n",
    "        y_train_binary = (y_train == i)\n",
    "        clf.fit(x_train, y_train_binary)\n",
    "        classifiers.append(clf)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(len(x_test)):\n",
    "        scores = []\n",
    "        for clf in classifiers:\n",
    "            score = clf.predict_proba([x_test[i]])[0][1]\n",
    "            scores.append(score)\n",
    "        y_pred.append(scores.index(max(scores)))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('Accuracy:', accuracy)\n",
    "    # return classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15588\\81320191.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain_decisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# 5. Make predictions on new examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15588\\1203405096.py\u001b[0m in \u001b[0;36mtrain_decisionTree\u001b[1;34m(x_train, y_train, x_test, y_test, first_class_index)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# 1. Prepare your data\n",
    "# X, y = load_iris(return_X_y=True) # load the iris dataset\n",
    "\n",
    "# 2. Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train_decisionTree(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# 5. Make predictions on new examples\n",
    "# new_example = [5.1, 3.5, 1.4, 0.2] # example input features\n",
    "# scores = []\n",
    "# for clf in models:\n",
    "#     score = clf.predict_proba([new_example])[0][1]\n",
    "#     scores.append(score)\n",
    "# class_pred = scores.index(max(scores))\n",
    "# print('Predicted class:', class_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_randomForest(x_train, y_train, x_test, y_test, n_ofTrees):\n",
    "    clf = RandomForestClassifier(n_estimators=n_ofTrees, max_depth=7, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # Evaluate the performance of the model\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9759036144578314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Generate random dataset for classification\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=3, random_state=42)\n",
    "#read X, y from df\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = train_randomForest(X_train, y_train, X_test, y_test, 100)\n",
    "# Create a random forest classifier\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the testing data\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance of the model\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "# print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "# print(\"F1-score:\", f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# X, y = load_digits(return_X_y=True)\n",
    "# naive_bayes = GaussianNB()\n",
    "# svc = SVC(kernel=\"rbf\", gamma=0.001)\n",
    "# The from_estimator displays the learning curve given the dataset and the predictive model to analyze. To get an estimate of the scores uncertainty, this method uses a cross-validation procedure.\n",
    "\n",
    "# from sklearn.model_selection import *\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 6), sharey=True)\n",
    "\n",
    "# common_params = {\n",
    "#     \"X\": X,\n",
    "#     \"y\": y,\n",
    "#     \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "#     \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "#     \"score_type\": \"both\",\n",
    "#     \"n_jobs\": 4,\n",
    "#     \"line_kw\": {\"marker\": \"o\"},\n",
    "#     \"std_display_style\": \"fill_between\",\n",
    "#     \"score_name\": \"Accuracy\",\n",
    "# }\n",
    "\n",
    "# for estimator in enumerate([clf]):\n",
    "#     LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[estimator])\n",
    "#     handles, label = ax[estimator].get_legend_handles_labels()\n",
    "#     ax[estimator].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "#     ax[estimator].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naiveBayes(x_train, y_train):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "# select top n features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a Pandas DataFrame\n",
    "# train_data = ['this is the first document', 'this is the second document', 'and this is the third document']\n",
    "\n",
    "# # Define the target classes\n",
    "# target_classes = ['class1', 'class2', 'class3']\n",
    "\n",
    "# #convert to data frame\n",
    "# data = pd.DataFrame({'text': train_data, 'target': target_classes})\n",
    "\n",
    "\n",
    "# Define the input features and target variable\n",
    "# X = data['text']\n",
    "# y = data['target']\n",
    "\n",
    "# Create a CountVectorizer object to convert text into numerical features\n",
    "# vectorizer = CountVectorizer()\n",
    "\n",
    "# # Convert the input features into a matrix of numerical features\n",
    "# X_matrix = vectorizer.fit_transform(X_train)\n",
    "\n",
    "model = train_naiveBayes(X_train, y_train) \n",
    "\n",
    "# Create a Multinomial Naive Bayes classifier object\n",
    "# clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the input features and target variable\n",
    "# clf.fit(X_matrix, y)\n",
    "\n",
    "# Use the classifier to predict the class of a new document\n",
    "# new_doc = 'this is a new document'\n",
    "# new_doc_matrix = vectorizer.transform(X_test)\n",
    "# predicted_class = model.predict(X_test)\n",
    "# print(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Slection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.927710843373494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15588\\1213277719.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_features['target'] = df['target']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import matplotlib.pyplot as plt\n",
    "importance = mutual_info_classif(X,y)\n",
    "feat_importance = pd.Series(importance , X.columns[0:len(df.columns)-2])\n",
    "#sortthe features \n",
    "feat_importance = feat_importance.sort_values(ascending=False)\n",
    "\n",
    "#loop on sorted features and print \n",
    "selected_features = []\n",
    "for i in feat_importance.index:\n",
    "    if feat_importance[i] > 0.02:\n",
    "        # print(i,feat_importance[i])\n",
    "        selected_features.append(i)\n",
    "\n",
    "# selected_features\n",
    "\n",
    "# create a data frame of the selected features\n",
    "df_selected_features = df[selected_features]\n",
    "df_selected_features['target'] = df['target']\n",
    "df_selected_features.head()\n",
    "\n",
    "X = df_selected_features\n",
    "y = df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = train_randomForest(X_train, y_train, X_test, y_test, 7)\n",
    "\n",
    "# X.plot(kind=\"box\",subplots=True,layout=(7,6),figsize=(20,18))\n",
    "# plt.show()\n",
    "\n",
    "# feat_importance.plot(kind='barh', color = 'black')\n",
    "\n",
    "# plt.show()\n",
    "# feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_features=df_selected_features[df_selected_features['HRV_ShanEn'] < 1.05]\n",
    "df_selected_features=df_selected_features[df_selected_features['HRV_ShanEn'] > 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_features=df_selected_features[df_selected_features['HRV_HTI'] < 1.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_features=df_selected_features[df_selected_features['HRV_ApEn'] < 1.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_selected_features=df_selected_features[df_selected_features['HRV_MFDFA_alpha1_Mean'] < 2.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_features=df_selected_features[df_selected_features['HRV_SD2'] < 2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9743589743589743\n"
     ]
    }
   ],
   "source": [
    "X = df_selected_features\n",
    "y = df_selected_features.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = train_randomForest(X_train, y_train, X_test, y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
